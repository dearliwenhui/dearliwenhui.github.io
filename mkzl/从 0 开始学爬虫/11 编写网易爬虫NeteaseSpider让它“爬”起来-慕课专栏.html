<html><head><meta charset="utf-8"><title>11 编写网易爬虫NeteaseSpider让它“爬”起来-慕课专栏</title>
			<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
			<meta name="renderer" content="webkit">
			<meta property="qc:admins" content="77103107776157736375">
			<meta property="wb:webmaster" content="c4f857219bfae3cb">
			<meta http-equiv="Access-Control-Allow-Origin" content="*">
			<meta http-equiv="Cache-Control" content="no-transform ">
			<meta http-equiv="Cache-Control" content="no-siteapp">
			<link rel="apple-touch-icon" sizes="76x76" href="https://www.imooc.com/static/img/common/touch-icon-ipad.png">
			<link rel="apple-touch-icon" sizes="120x120" href="https://www.imooc.com/static/img/common/touch-icon-iphone-retina.png">
			<link rel="apple-touch-icon" sizes="152x152" href="https://www.imooc.com/static/img/common/touch-icon-ipad-retina.png">
			<link href="https://moco.imooc.com/captcha/style/captcha.min.css" rel="stylesheet">
			<link rel="stylesheet" href="https://www.imooc.com/static/moco/v1.0/dist/css/moco.min.css?t=201907021539" type="text/css">
			<link rel="stylesheet" href="https://www.imooc.com/static/lib/swiper/swiper-3.4.2.min.css?t=201907021539">
			<link rel="stylesheet" href="https://static.mukewang.com/static/css/??base.css,common/common-less.css?t=2.5,column/zhuanlanChapter-less.css?t=2.5,course/inc/course_tipoff-less.css?t=2.5?v=201907051055" type="text/css">
			<link charset="utf-8" rel="stylesheet" href="https://www.imooc.com/static/lib/ueditor/themes/imooc/css/ueditor.css?v=201907021539"><link rel="stylesheet" href="https://www.imooc.com/static/lib/baiduShare/api/css/share_style0_16.css?v=6aba13f0.css"></head>
			<body><div id="main">

<div class="container clearfix" id="top" style="display: block; width: 1134px;">
    
    <div class="center_con js-center_con l" style="width: 1134px;">
        <div class="article-con">
                            <!-- 买过的阅读 -->
                <div class="map">
                    <a href="/read" target="_blank"><i class="imv2-feather-o"></i></a>
                    <a href="/read/34" target="_blank">从 0 开始学爬虫</a>
                    <a href="" target="_blank">
                        <span>
                            / 3-5 11 编写网易爬虫NeteaseSpider让它“爬”起来
                        </span>
                    </a>
                </div>

            


            <div class="art-title" style="margin-top: 0px;">
                11 编写网易爬虫NeteaseSpider让它“爬”起来
            </div>
            <div class="art-info">
                
                <span>
                    更新时间：2019-06-14 14:34:54
                </span>
            </div>
            <div class="art-top">
                                <img src="https://img.mukewang.com/5ce255810001bc6f06400359.jpg" alt="">
                                                <div class="famous-word-box">
                    <img src="https://www.imooc.com/static/img/column/bg-l.png" alt="" class="bg1 bg">
                    <img src="https://www.imooc.com/static/img/column/bg-r.png" alt="" class="bg2 bg">
                    <div class="famous-word">时间像海绵里的水，只要你愿意挤，总还是有的。<p class="author">——鲁迅</p></div>
                </div>
                            </div>
            <div class="art-content js-lookimg">
                <div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">将对目标网页的分析融入到爬虫代码中，怎样在蜘蛛内部用最简洁的办法从复杂的网页内容中提取数据。从认识 scrapy 的配置文件<code>settings.py</code>理解 scrapy 的组件化思想。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">在重新进入我们的网易爬虫示例之前，先来回顾一下前面章节的内容。首先在第一节我介绍了分页网页结构的基本方法与思路，重点是了解<code>&lt;a&gt;</code>和<code>&lt;link&gt;</code>这两类蜘蛛最关注元素，如果按层层步进的方式爬取网页内容称之为<strong>深度爬网</strong>，与之对应的是在同一链接层次上先爬取所有相邻页面节点的内容，再向下步进称之为<strong>广度爬网</strong>，还有就是将两者相结合的<strong>泛爬网</strong>方式。从这些爬取路径了解到蜘蛛是怎么在网站上<strong>爬行</strong>的。由此引入了<code>CrawlSpider</code>来实现<strong>泛爬</strong>。</p>
</div><div class="cl-preview-section"><h2 id="编写-neteasespider-蜘蛛" style="font-size: 30px;">编写 <code>NeteaseSpider</code> 蜘蛛</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">开始<code>CrawlSpider</code>的学习就很自然地接触到<strong>正则表达式</strong>，也从这个点上我用了整整三个小节来系统化地介绍了正则表达式的相关内容，其实当我们完全理解了正则表达式之后，就可以说是大体上掌握了对<code>CrawlSpider</code>的基本用法，它的主要使用路径可以总结如下：</p>
</div><div class="cl-preview-section"><ol>
<li style="font-size: 20px; line-height: 38px;">找出种子页</li>
<li style="font-size: 20px; line-height: 38px;">分析与定义Item类的结构</li>
<li style="font-size: 20px; line-height: 38px;">根据你的爬网策略编写<code>rules</code>属性内的爬网规则和链接提取器</li>
<li style="font-size: 20px; line-height: 38px;">编写<code>parse_item</code>方法分析网页的响应内容并从中提取出 Item 所需要的数据内容</li>
</ol>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">我们在第一节已经知道网易的网站结构是由多个不同子域来划分，例如：</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;"><a href="https://news.163.com">https://news.163.com</a> - 新闻</li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://wars.163.com">https://wars.163.com</a> - 军事</li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://sports.163.com">https://sports.163.com</a> -体育</li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://v.163.com">https://v.163.com</a> -直播</li>
<li style="font-size: 20px; line-height: 38px;">诸如此类</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">那么既然有这么多的子域，我们是不是都要一一加入到<code>start_urls</code>内作为种子页呢？对于这种问题可以分两种情况来分析：</p>
</div><div class="cl-preview-section"><ol>
<li style="font-size: 20px; line-height: 38px;">如果你已经很明确要爬取的内容是在哪个子域下，又或者你只想爬取某几个子域下的内容就可以在<code>start_urls</code>下进行逐一添加，并通过<code>allowed_domains</code>声明只可以爬取的域；</li>
<li style="font-size: 20px; line-height: 38px;">如果我们并不知道网站有多少个子域并且我们希望爬虫可以爬取整个网站内的每个子域，那么我们只需要将<code>www.163.com</code>(首页)作为唯一的种子页，由首页进入，对不符合目标网页的URL规则执行步进，当遇到符合规则的URL则进行数据的提取并停止步进。</li>
</ol>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">对于我们的示例将会采用第二种爬取策略，尽可能多地从网站中爬取各个栏目的内容。首先可以打开几个网易上的新闻详情页，不难发现这些页面都与以下的地址形式类似:</p>
</div><div class="cl-preview-section"><pre><code>https://news.163.com/19/0501/08/EE32CO3K000189FH.html
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">由此对URL进行一般化的定义：</p>
</div><div class="cl-preview-section"><pre><code>[协议定义]://[域]/[2位数字]/[4位数字]/[2位数字]/[页面名]
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">那么与之对应的正则表达式则如下所示：</p>
</div><div class="cl-preview-section"><pre><code>(\w+):\/\/([^/:]+)\/(\d{2})+\/(\d{4})+\/(\d{2})+\/([^#]*)
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">对于符合上述URL规则的地址就让蜘蛛执行<code>parse_item</code>方法。代码如下所示：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> Selector
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule
<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>items <span class="token keyword">import</span> NewsItem

<span class="token keyword">class</span> <span class="token class-name">NeteaseSpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'netease'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'163.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://163.com/'</span><span class="token punctuation">]</span>
    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
    Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span>r<span class="token string">'(\w+):\/\/([^/:]+)\/(\d{2})+\/(\d{4})+\/(\d{2})+\/([^#]*)'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
</code></pre>
</div><div class="cl-preview-section"><h2 id="编写-parse_item-分析代码" style="font-size: 30px;">编写 <code>parse_item</code> 分析代码</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">根据在第一节中对新闻详情页分析得出的元素与字段关系映射表：</p>
</div><div class="cl-preview-section"><div class="table-wrapper"><table>
<thead>
<tr>
<th>名称</th>
<th>字段</th>
<th>选择器</th>
</tr>
</thead>
<tbody>
<tr>
<td>标题</td>
<td>title</td>
<td><code>#epContentLeft&gt;h1</code></td>
</tr>
<tr>
<td>发表日期</td>
<td>pub_date</td>
<td><code>#epContentLeft .post_time_source</code></td>
</tr>
<tr>
<td>摘要</td>
<td>desc</td>
<td><code>#epContentLeft .post_desc</code></td>
</tr>
<tr>
<td>正文</td>
<td>body</td>
<td><code>#endText</code></td>
</tr>
<tr>
<td>链接</td>
<td>link</td>
<td>当前请求中的URL</td>
</tr>
</tbody>
</table>
</div></div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">很容易得到<code>parse_item</code>的代码内容：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
  item <span class="token operator">=</span> NewsItem<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># NewsItem编写详情见本章第一小节</span>
  selector <span class="token operator">=</span> Selector<span class="token punctuation">(</span>response<span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> selector<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'#epContentLeft&gt;h1::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'pub_date'</span><span class="token punctuation">]</span> <span class="token operator">=</span> selector<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'#epContentLeft .post_time_source::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> item<span class="token punctuation">[</span><span class="token string">'pub_date'</span><span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    item<span class="token punctuation">[</span><span class="token string">'pub_date'</span><span class="token punctuation">]</span> <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'pub_date'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
  item<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span> <span class="token operator">=</span> selector<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'#epContentLeft .post_desc::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> item<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    item<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span> <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'body'</span><span class="token punctuation">]</span> <span class="token operator">=</span> selector<span class="token punctuation">.</span>css<span class="token punctuation">(</span><span class="token string">'#endText::text'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> item<span class="token punctuation">[</span><span class="token string">'body'</span><span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    item<span class="token punctuation">[</span><span class="token string">'body'</span><span class="token punctuation">]</span> <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'body'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'link'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>url
  <span class="token keyword">return</span> item
</code></pre>
</div><div class="cl-preview-section"><h2 id="深入选择器-xpath-css" style="font-size: 30px;">深入选择器 xpath, css</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">我在"动手开发最简单的单文件爬虫"一节中就使用过<code>pyQuery</code>对返回的响应内容进行分析提取，如果由此入手去百度或谷歌一下你会发现不少关于 beautifulsoup4 与 pyQuery 的对比的文章，过去我曾对此产生过选择困难症：到底 beautifulsoup4、pyQuery 和 Scrapy 内自带的选择器到底哪个更好呢 ？</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">我们就借本节的示例用具体代码来对比一下这三者的优劣然后再作出选择，首先是<a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/#">beautifulsoup4</a> ，用bs4的<code>parse_item</code>代码如下所示：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

<span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
  soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>
  item <span class="token operator">=</span> NewsItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#epContentLeft&gt;h1'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'pub_date'</span><span class="token punctuation">]</span> <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#epContentLeft .post_time_source'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span> <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#epContentLeft .post_desc'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'body'</span><span class="token punctuation">]</span> <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#endText'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> item
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果换成pyQuery则代码如下所示：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">from</span> pyQuery <span class="token keyword">import</span> PyQuery <span class="token keyword">as</span> pq

<span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
  doc <span class="token operator">=</span> pq<span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">)</span>
  item <span class="token operator">=</span> NewsItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> doc<span class="token punctuation">(</span><span class="token string">'#epContentLeft&gt;h1'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'pub_date'</span><span class="token punctuation">]</span> <span class="token operator">=</span> doc<span class="token punctuation">(</span><span class="token string">'#epContentLeft .post_time_source'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span> <span class="token operator">=</span> doc<span class="token punctuation">(</span><span class="token string">'#epContentLeft .post_desc'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span>
  item<span class="token punctuation">[</span><span class="token string">'body'</span><span class="token punctuation">]</span> <span class="token operator">=</span> doc<span class="token punctuation">(</span><span class="token string">'#endText'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> item
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">beautifulsoup4、pyQuery 在具体使用时两者语法大同小异，bs4 更 python 化一点，而 pyQuery 则更像python中的jQuery。bs4 年代比较久远名声也大一些，不过性能确实很差。对爬取任务量巨大(爬取量在万级以上)时会有很明显的速度滞后的感觉，而且它对内存的消耗也比较大。而 pyQuery 则比 bs4 的性能要好一些，如果你曾对 jQuery 非常熟悉的话也推荐使用 pyQuery。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果对 bs4 与 pyQuery 本身都没有什么认知的话，我建议"两者皆可抛"，直接使用 Scrapy 自带的选择器就好了，毕竟这是学习成本最低的，而且 Scrapy 自带的选择器速度一定不比前两者慢，甚至更好一些。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy 提供了 xpath 和 CSS 两种选择器，如果你熟悉XPath 那当然使用 XPath 的选择语法一定是速度最高的。悻然，即使你不懂XPath语法只学会 CSS 选择器的语法也能有 XPath 的分析速度，那是因为 Scrapy 会将 CSS 选择器直接转换为 XPath！这也是 Scrapy 在不断迭代更新后的一个非常友好的功能，如果去查看<code>scrapy.Selector.css</code>方法的源代码，你会发现这个方法是调用了<code>Selector</code>内部的一个<code>_css2xpath</code>方法实现的，<code>_css2xpath</code>正是一个自动将css选择器语法转成xpath语法的私有方法。我是个崇尚简洁实用主义的开发者，所以在 bs4 , pyQuery 和 Selector 这三者之间，我会推荐你使用学习成本最低，速度最高的<code>scrapy.Selector</code>。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">编写完<code>parse_item</code>方法，这个网易爬虫也可以宣告完成，在终端执行以下指令来执行：</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy crawl netease -o netease.json -s FEED_EXPORT_ENCODING='utf-8'
</code></pre>
</div><div class="cl-preview-section"><h2 id="认识基本配置-——-scrapy-的组件化设计思想" style="font-size: 30px;">认识基本配置 —— scrapy 的组件化设计思想</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy是由核心（core）模块、扩展插件（extension）、蜘蛛(spider)、管道(pipeline)、下载器中间件(Download middleware)和存储后端(Storage Backend)等多个部分的组成，这些模块各自负责爬取过程中对应环节中的某项细化的处理。默认情况下我们只需要编写蜘蛛就能完成基本的爬网任务，对于不同的爬取场景我们能通过修改模块的配置甚至增加某些定义的模块就能适应具体的爬取场景。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy这种强大的可自由组合与自由<strong>装配</strong>的能力得益于它高度组件化的设计理念。<strong>每个模块只做一件事</strong>，这是一种设计原则称为“单一职责原则“，模块之间相对独立，它们能被组合在一起协同工作依赖于Scrapy引擎在执行爬取时根据<code>settings.py</code>配置的内容对各个模块的的运行参数进行微调、将自定义的模块装配到Scrapy的执行环境中。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy配置文件<code>settings.py</code>有很多的配置项，如果一股脑地去理解其中的内容并不容易，按照本专栏的思路我们可以从最常用最简单的入手，从本章示例开始我们将会频繁地与这个<code>settings.py</code>文件打交道。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">当我们使用<code>scrapy startproject</code>指令创建爬虫项目后 Scrapy 就会创建一个默认的<code>settings.py</code>文件，这个文件内有很多的注释项，我们可以暂时保留并忽略它们。在我们后面的内容中对最要的配置项目都会一一提及（详细的<code>settings.py</code>的配置可以<a href="https://doc.scrapy.org/en/latest/topics/settings.html">参见官方说明</a>）。打开<code>settings.py</code>文件，具体内容如下所示:</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">BOT_NAME <span class="token operator">=</span> <span class="token string">'netease'</span>

SPIDER_MODULES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'netease_crawler.spiders'</span><span class="token punctuation">]</span>
NEWSPIDER_MODULE <span class="token operator">=</span> <span class="token string">'netease_crawler.spiders'</span>

<span class="token comment"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">True</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">上面例出的4个配置是最重要的配置项，<code>BOT_NAME</code>是声明当前爬虫项目默认的蜘蛛名称，这个名字必须与蜘蛛的<code>name</code>属性相同。</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">class</span> <span class="token class-name">NeteaseSpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'netease'</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><code>SPIDER_MODULES</code>是声明所有蜘蛛模块的命名空间，<code>NEWSPIDER_MODULE</code>是指向<code>BOT_NAME</code>所在的蜘蛛的命名空间，如果在创建项目后没有更改文件名或文件夹的情况下，这两个设置是不需要变动的。</p>
</div><div class="cl-preview-section"><h3 id="robot.txt"><code>robot.txt</code></h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><code>ROBOTSTXT_OBEY</code> 是声明是否在爬取之前先获取目标网站上的<code>robot.txt</code>文件，然后让蜘蛛根据<code>robot.txt</code>文件中制定的规则进行爬取。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><a href="https://baike.baidu.com/item/robot.txt">robot.txt</a> 是一个纯文本文件，是网站用来专门告诉爬虫，网站内哪些内容可以爬哪些内容不希望爬虫进入的一个文件。这个文件是网站对爬虫的一种<strong>礼遇</strong>，如果爬虫按照里面的规定<strong>有礼貌</strong>地爬取内容，一般上是不会触发网站的反爬机制。这只是一份<strong>君子协议</strong>，爬虫是可以不遵守这份协定而突破网站的任意区域获取数据的，但会触发什么后果也只能是"看着办"。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">robot.txt 文件的内容非常简单，只有两个配置:</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;"><code>User-agent</code> - 声明只允许哪些浏览器进入，如果被设置为<code>*</code>则是说明任意的浏览器都可以访问(在后面的反爬技术章节中会有专门讲述这个User Agent的内容)</li>
<li style="font-size: 20px; line-height: 38px;"><code>Disallow</code> - 声明哪些URL下的内容是不允许爬虫进入的。(可以有多行的声明)</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">robot.txt 是一个由来已久的协定，最初是为了给搜索引擎的蜘蛛准备的，用于屏蔽掉一些对于搜索引擎蜘蛛无用的文件，避免索引质量下降而采用的协定。我们之所以要知道它，是因为我们的爬虫也可以<strong>装</strong>作是一种搜索引擎发出的蜘蛛，从最小的程度上<strong>麻痹</strong>对方的反爬机制。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">以上是一种背景知识，因为Scrapy会默认让蜘蛛遵守<code>robot.txt</code>的协议内容的，当<code>ROBOTSTXT_OBEY</code>被设置为<code>True</code> 时，如果对方网站的根目录下根本没有放置 robot.txt文件，会导致爬虫执行失败的，所以推荐这个选项设置为<code>False</code> :</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">ROBOTSTXT_OBEY<span class="token operator">=</span><span class="token boolean">False</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">为了让爬虫的执行速度能更快，建议将以下的选项打开（将配置项的注释去掉就好）:</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">HTTPCACHE_ENABLED <span class="token operator">=</span> <span class="token boolean">True</span>
TELNETCONSOLE_ENABLED <span class="token operator">=</span> <span class="token boolean">False</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><code>HTTPCACHE_ENABLED</code>会将爬取过的内容自动存到本地，下次重复爬取相同URL时就直接从本地的文件中读取而不再向网站发出请求，这个功能在开发期需要反复调试爬虫的情况是非常有用的。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><code>TELNETCONSOLE_ENABLED</code> 这个选项是被默认打开的，它的作用就是打开一个 Telnet 服务让我们可以通过终端用 Telnet 来与 Scrapy 的爬虫实例进行观察，这是一种非常古老的调试手段了，而且它的启动很影响性能，所以建议将这个选项直接关闭。如果对Telnet调试有兴趣的读者可以参考<a href="https://doc.scrapy.org/en/latest/topics/telnetconsole.html">官方关于Telnet的控制台</a>的内容</p>
</div><div class="cl-preview-section"><h3 id="保存-item-到-json-的方法">保存 Item 到 JSON 的方法</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果执行爬虫的命令行参数过多，实在是一种非常不友好的使用方式：</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy crawl netease -o netease.json -s FEED_EXPORT_ENCODING='utf-8'
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">我们同样可以通过配置文件<code>settings.py</code>来简化执行指令，具体配置方法如下所示：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">FEED_FORMAT <span class="token operator">=</span> <span class="token string">'json'</span>
FEED_URI <span class="token operator">=</span> <span class="token string">'result.json'</span>
FEED_EXPORT_ENCODING<span class="token operator">=</span><span class="token string">'utf-8'</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">用<code>FEED_FORMAT</code>与<code>FEED_URI</code>取代输出参数<code>-o</code>，直接指定输出格式与输出文件位置。(Windows环境下需指定<code>FEED_URI</code>的绝对路径，如<code>file:///D:/Spider/netease_crawler/result.json</code>)。<code>FEED_EXPORT_ENCODING</code>指定输出文件的编码方式以解决中文乱码的问题。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">至此，我们可以得到一份完整实用的<code>settings.py</code>配置文件：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">BOT_NAME <span class="token operator">=</span> <span class="token string">'netease'</span>

SPIDER_MODULES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'netease_crawler.spiders'</span><span class="token punctuation">]</span>
NEWSPIDER_MODULE <span class="token operator">=</span> <span class="token string">'netease_crawler.spiders'</span>

ROBOTSTXT_OBEY<span class="token operator">=</span><span class="token boolean">False</span>
HTTPCACHE_ENABLED <span class="token operator">=</span> <span class="token boolean">True</span>
TELNETCONSOLE_ENABLED <span class="token operator">=</span> <span class="token boolean">False</span>

FEED_FORMAT <span class="token operator">=</span> <span class="token string">'json'</span>
FEED_URI <span class="token operator">=</span> <span class="token string">'result.json'</span>
FEED_EXPORT_ENCODING<span class="token operator">=</span><span class="token string">'utf-8'</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">完成配置工作后只要按如下方式启动执行爬网就可以了</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy crawl netease
</code></pre>
</div><div class="cl-preview-section"><h2 id="小结" style="font-size: 30px;">小结</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">虽然本章用了五个小节来讲述一个"网易泛爬蜘蛛"开发过程，实际上代码量只是非常少量。只要你运行起这个爬虫就会发现它的性能惊人，在一个小时内<code>result.json</code>的大小已经超过几百兆，请注意这可是纯文本的内容！</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">一但我们站在蜘蛛的视觉角度建立起一张可爬行的蜘网的概念，用正则表达式来提取出这个网的规则，完全掌握页面分析与数据提取的方法，无论面对规模多么庞大的网站，蜘蛛都可以畅通无阻地在其中穿行。<br>
<img src="http://img.mukewang.com/5cef89a50001eeb916000755.jpg" alt="图片描述" data-original="http://img.mukewang.com/5cef89a50001eeb916000755.jpg" class="" style="cursor: pointer;"></p>
</div><div class="cl-preview-section"><blockquote>
<p style="font-size: 20px; line-height: 38px;">注：你可以去<a href="https://github.com/DotNetAge/netease_crawler">GitHub</a>获取本章源代码</p>
</blockquote>
</div></div>
            </div>
                            <!-- 买过的阅读 -->
                <div class="art-next-prev clearfix">
                                                                        <!-- 已买且开放 或者可以试读 -->
                            <a href="/read/34/article/312">
                                                    <div class="prev l clearfix">
                                <div class="icon l">
                                    <i class="imv2-arrow3_l"></i>
                                </div>
                                <p>
                                    10 Python中的正则表达式用法
                                </p>
                            </div>
                        </a>
                                                                                            <!-- 已买且开放 或者可以试读 -->
                            <a href="/read/34/article/317">
                                                    <div class="next r clearfix">
                                <p>
                                    12 用 ItemLoader 解决网页数据多样性的问题
                                </p>
                                <div class="icon r">
                                    <i class="imv2-arrow3_r"></i>
                                </div>

                            </div>
                        </a>
                                    </div>
                    </div>
        <div class="comments-con js-comments-con" id="coments_con">
        </div>



    </div>
    
    
    

</div>
 
<!-- 专栏介绍页专栏评价 -->

<!-- 专栏介绍页底部三条评价 -->

<!-- 专栏阅读页弹层目录和介绍页页面目录 -->

<!-- 专栏阅读页发布回复 -->

<!-- 专栏阅读页发布评论 -->

<!-- 专栏阅读页底部评论 -->

<!-- 专栏阅读 单个 评论 -->

<!-- 新增回复和展开三条以外回复 -->

<!-- 立即订阅的弹窗 -->












</div></body></html>