<html><head><meta charset="utf-8"><title>15 为网易爬虫配置存储大规模数据存储 -慕课专栏</title>
			<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
			<meta name="renderer" content="webkit">
			<meta property="qc:admins" content="77103107776157736375">
			<meta property="wb:webmaster" content="c4f857219bfae3cb">
			<meta http-equiv="Access-Control-Allow-Origin" content="*">
			<meta http-equiv="Cache-Control" content="no-transform ">
			<meta http-equiv="Cache-Control" content="no-siteapp">
			<link rel="apple-touch-icon" sizes="76x76" href="https://www.imooc.com/static/img/common/touch-icon-ipad.png">
			<link rel="apple-touch-icon" sizes="120x120" href="https://www.imooc.com/static/img/common/touch-icon-iphone-retina.png">
			<link rel="apple-touch-icon" sizes="152x152" href="https://www.imooc.com/static/img/common/touch-icon-ipad-retina.png">
			<link href="https://moco.imooc.com/captcha/style/captcha.min.css" rel="stylesheet">
			<link rel="stylesheet" href="https://www.imooc.com/static/moco/v1.0/dist/css/moco.min.css?t=201907021539" type="text/css">
			<link rel="stylesheet" href="https://www.imooc.com/static/lib/swiper/swiper-3.4.2.min.css?t=201907021539">
			<link rel="stylesheet" href="https://static.mukewang.com/static/css/??base.css,common/common-less.css?t=2.5,column/zhuanlanChapter-less.css?t=2.5,course/inc/course_tipoff-less.css?t=2.5?v=201907051055" type="text/css">
			<link charset="utf-8" rel="stylesheet" href="https://www.imooc.com/static/lib/ueditor/themes/imooc/css/ueditor.css?v=201907021539"><link rel="stylesheet" href="https://www.imooc.com/static/lib/baiduShare/api/css/share_style0_16.css?v=6aba13f0.css"></head>
			<body><div id="main">

<div class="container clearfix" id="top" style="display: block; width: 1134px;">
    
    <div class="center_con js-center_con l" style="width: 1134px;">
        <div class="article-con">
                            <!-- 买过的阅读 -->
                <div class="map">
                    <a href="/read" target="_blank"><i class="imv2-feather-o"></i></a>
                    <a href="/read/34" target="_blank">从 0 开始学爬虫</a>
                    <a href="" target="_blank">
                        <span>
                            / 4-4 15 为网易爬虫配置存储大规模数据存储 
                        </span>
                    </a>
                </div>

            


            <div class="art-title" style="margin-top: 0px;">
                15 为网易爬虫配置存储大规模数据存储 
            </div>
            <div class="art-info">
                
                <span>
                    更新时间：2019-06-14 14:35:43
                </span>
            </div>
            <div class="art-top">
                                <img src="https://img1.mukewang.com/5cebc8160001164c06400360.jpg" alt="">
                                                <div class="famous-word-box">
                    <img src="https://www.imooc.com/static/img/column/bg-l.png" alt="" class="bg1 bg">
                    <img src="https://www.imooc.com/static/img/column/bg-r.png" alt="" class="bg2 bg">
                    <div class="famous-word">困难只能吓倒懦夫懒汉，而胜利永远属于敢于等科学高峰的人。<p class="author">——茅以升</p></div>
                </div>
                            </div>
            <div class="art-content js-lookimg">
                <div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">增量式爬虫面对的是逐渐增加的海量数据，显然用文件作为提取数据的存储媒介是完全不能满足其后续的需要的。本节将介绍如何把从网易提取到的巨量数据存储到与 Scrapy 天生契合的 NoSQL 数据库 MongoDB 中。</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;">什么是 Pipeline? 在 Scrapy 中有何作用 ？</li>
<li style="font-size: 20px; line-height: 38px;">如何编写 Pipeline - <code>ItemPipeline</code>的介绍</li>
<li style="font-size: 20px; line-height: 38px;">编写<code>MongoPipeline</code>
<ul>
<li style="font-size: 20px; line-height: 38px;">安装 pyMongo</li>
<li style="font-size: 20px; line-height: 38px;">如何在 Pipeline 中读取 Pipeline 的配置</li>
<li style="font-size: 20px; line-height: 38px;">丢弃无效的数据项目 <code>DropItem</code></li>
<li style="font-size: 20px; line-height: 38px;">将 Item 写入 MongoDB</li>
<li style="font-size: 20px; line-height: 38px;">log 输出写入结果</li>
</ul>
</li>
<li style="font-size: 20px; line-height: 38px;">如何安装 MongoDB - Docker</li>
<li style="font-size: 20px; line-height: 38px;">使用MongoDB Compress 查看网易文章爬取结果并进行数据结构调优</li>
<li style="font-size: 20px; line-height: 38px;">小结</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果持续运行网易爬虫你会发现的<code>result.json</code>文件很快就变成一个体积巨大的文本，超过200M以后就基本打不开了。面对像网易爬虫这种要应对海量爬取数据的项目单纯将数据结果写入到一个JSON文本的方式已经显得不可取。在这种情况下我们需要使用数据库来处理这种大规模的数据存储。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">为了可以像处理JSON一样方便地逐个处理请求结果，本节将会使用<a href="%5Bhttp://www.mongodb.org.cn/%5D(http://www.mongodb.org.cn/)">MongoDB</a>作为爬虫项目的后端存储，使用管道(Pipleline)来向MongoDB写入数据。</p>
</div><div class="cl-preview-section"><h2 id="什么是-pipeline-在-scrapy-中有何作用-？" style="font-size: 30px;">什么是 Pipeline? 在 Scrapy 中有何作用 ？</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">当数据项(<code>Item</code>)在蜘蛛(Spider)中被收集之后，它将会被Scrapy传递到管道中（Item Pipeline），Scrapy会按照一定的顺序将数据项（Item）传入管道执行处理，简言之：<strong>管道就是针对单个数据项(Item)的处理器</strong>。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">每个管道(“Item Pipeline”)是实现了简单方法的Python类。它们接收Item并对Item执行一些特定的处理，也决定此数据项(Item)是否能继续通过管道向下一个管道传递（直接丢弃）。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">以下是管道的一些典型应用：</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;">清理HTML数据；</li>
<li style="font-size: 20px; line-height: 38px;">验证爬取的数据(检查Item包含某些字段)；</li>
<li style="font-size: 20px; line-height: 38px;">清洗不合格规范的数项；</li>
<li style="font-size: 20px; line-height: 38px;">将数据项写入到数据库；</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">除了以上的几种应用，其实管道可以处理任意与Item相关（丢弃与继续）的事务。</p>
</div><div class="cl-preview-section"><h2 id="如何编写-pipeline---itempipeline的介绍" style="font-size: 30px;">如何编写 Pipeline - <code>ItemPipeline</code>的介绍</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">编写自定义的管道非常简单，每个管道都是一个具有<code>process_item</code>方法的Python类，具体如下所示。</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">class</span> <span class="token class-name">MyPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> item
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">每个管道都需要调用<code>process_item</code>方法，而且这个方法<strong>必须</strong>返回一个<code>Item</code>对象或是抛出一个<code>DropItem</code>异常。以下是<code>process_item</code>方法的参数说明：</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;"><code>item</code>——当前处理的Item对象；</li>
<li style="font-size: 20px; line-height: 38px;"><code>spider</code>——产生当前Item对象的蜘蛛实例。</li>
</ul>
</div><div class="cl-preview-section"><blockquote>
<p style="font-size: 20px; line-height: 38px;">注意：管道每次只处理一个Item对象。</p>
</blockquote>
</div><div class="cl-preview-section"><h2 id="编写mongodbpipeline" style="font-size: 30px;">编写<code>MongoDBPipeline</code></h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">接下来我们编写一个<code>MongoDBPipeline</code>用于向MongoDB插入爬取的文章内容。</p>
</div><div class="cl-preview-section"><h3 id="mongodb简介">MongoDB简介</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">MongoDB是一个文档型的非关系数据库产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。</p>
</div><div class="cl-preview-section"><h3 id="mongodb的基本概念">MongoDB的基本概念</h3>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;">文档：是MongoDB中数据的基本单元，非常类似于关系型数据库系统中的行（但是比行要复杂很多）</li>
<li style="font-size: 20px; line-height: 38px;">集合：就是一组文档，如果说MongoDB中的文档类似于关系型数据库中的行，那么集合就如同表</li>
<li style="font-size: 20px; line-height: 38px;">MongoDB的单个计算机可以容纳多个独立的数据库，每一个数据库都有自己的集合和权限</li>
<li style="font-size: 20px; line-height: 38px;">MongoDB自带简洁但功能强大的JavaScript shell，这个工具对于管理MongoDB实例和操作数据库作用非常大</li>
<li style="font-size: 20px; line-height: 38px;">每一个文档都有一个特殊的键"_id",它在文档所处的集合中是唯一的，相当于关系数据库中的表的主键</li>
</ul>
</div><div class="cl-preview-section"><h3 id="安装-pymongo">安装 pyMongo</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">要在python中访问MongoDB推荐使用<a href="https://api.mongodb.com/python/current/">pyMongo</a>，这是由MongoDB官方提供的python客户端。在虚环境下安装pyMongo:</p>
</div><div class="cl-preview-section"><pre><code>$ pip install pyMongo
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">pyMongo的使用非常简单，首先需要实例化一个<code>MongoClient</code>类，通过这个类与MongoDB进行连接后就能对数据库进行常规的CRUD操作了，具体如下：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">import</span> pymongo
connection <span class="token operator">=</span> pymongo<span class="token punctuation">.</span>MongoClient<span class="token punctuation">(</span><span class="token string">'localhost'</span><span class="token punctuation">,</span><span class="token number">27017</span><span class="token punctuation">)</span> <span class="token comment">#连接MongoDB</span>
db <span class="token operator">=</span> connection<span class="token punctuation">[</span><span class="token string">'数据库名称'</span><span class="token punctuation">]</span> <span class="token comment"># 获取数据库实例</span>
collection <span class="token operator">=</span> db<span class="token punctuation">[</span><span class="token string">'数据集名称'</span><span class="token punctuation">]</span> <span class="token comment"># 获取数据集实例(相当于数据表)</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">当获得<code>collection</code>就可以进行对象操作了。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">与MongoDB的连接可以只在管道实例化时进行，并将<code>collection</code>存为管道对象的内部属性这样就无需要每操作一个数据项都与MongoDB发生一次连接，避免额外的资源消耗。具体代码如下：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">import</span> pymongo

<span class="token keyword">class</span> <span class="token class-name">MongoDBPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    MongoDB数据管道
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> server<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> db_name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> col<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        connection <span class="token operator">=</span> pymongo<span class="token punctuation">.</span>MongoClient<span class="token punctuation">(</span>server<span class="token punctuation">,</span> port<span class="token punctuation">)</span>
        db <span class="token operator">=</span> connection<span class="token punctuation">[</span>db_name<span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>collection <span class="token operator">=</span> db<span class="token punctuation">[</span>col<span class="token punctuation">]</span>

</code></pre>
</div><div class="cl-preview-section"><h3 id="如何在-pipeline-中读取-pipeline-的配置">如何在 Pipeline 中读取 Pipeline 的配置</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">与我们上两章介绍的去重处理器稍有不同，管道并不是从<code>from_settings</code>的类级方法来让Scrapy"注入"配置对象,而改用了<code>from_cralwer</code>这个方法，这一点必须注意：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">@<span class="token builtin">classmethod</span>
<span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
  server <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'MONGODB_SERVER'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  port <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>getint<span class="token punctuation">(</span><span class="token string">'MONGODB_PORT'</span><span class="token punctuation">)</span>
  db_name <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'MONGODB_DB'</span><span class="token punctuation">)</span>
  collection_name <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'MONGODB_COLLECTION'</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> cls<span class="token punctuation">(</span>server<span class="token punctuation">,</span> port<span class="token punctuation">,</span> db_name<span class="token punctuation">,</span> collection_name<span class="token punctuation">)</span>

</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">这样就为<code>settings.py</code>增加了适用于<code>MongoDBPipeline</code>的配置项，具体如下所示：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token comment"># settings.py</span>
MONGODB_SERVER <span class="token operator">=</span> <span class="token string">"localhost"</span>
MONGODB_PORT <span class="token operator">=</span> <span class="token number">27017</span>
MONGODB_DB <span class="token operator">=</span> <span class="token string">"数据库名"</span>
MONGODB_COLLECTION <span class="token operator">=</span> <span class="token string">"表名"</span>
</code></pre>
</div><div class="cl-preview-section"><h3 id="将-item-写入-mongodb">将 Item 写入 MongoDB</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">MongoDB的使用有点像传统的SQL数据库，一开始要建立一个数据库连接，然后是获得数据库的实例，接着是得到具体集合(表)的实例，最后才是向集合写入数据 。如果频繁建立数据库的连接会对服务器的资源产生巨大的消耗，所以我们可以在蜘蛛启动时打开连接，蜘蛛完成爬取任务时关闭数据库连接。这样做就可以避免做无用功消耗不必要的资源。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">在<code>ItemPipline</code>可以增加<code>open_spider</code>和<code>close_spider</code>这两个方法分别向蜘蛛打开事件与蜘蛛关闭事件加入特定的处理，具体如下所示：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
  self<span class="token punctuation">.</span>connection <span class="token operator">=</span> pymongo<span class="token punctuation">.</span>MongoClient<span class="token punctuation">(</span>self<span class="token punctuation">.</span>server<span class="token punctuation">,</span> self<span class="token punctuation">.</span>port<span class="token punctuation">)</span>
  self<span class="token punctuation">.</span>db <span class="token operator">=</span> self<span class="token punctuation">.</span>connection<span class="token punctuation">[</span>self<span class="token punctuation">.</span>db_name<span class="token punctuation">]</span>
  self<span class="token punctuation">.</span>collection <span class="token operator">=</span> self<span class="token punctuation">.</span>db<span class="token punctuation">[</span>self<span class="token punctuation">.</span>col<span class="token punctuation">]</span>

  <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>connection<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">最后就是向MongoDB插入数据了，向MongoDB插入数据是最简单的操作，只要调用<code>MongoClient</code>的<code>insert</code>方法并将数据项作为字典对象插入即可，具体如下所示：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>item<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
	  self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> item
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">这就大功告成了，是不是很简单呢？</p>
</div><div class="cl-preview-section"><h3 id="丢弃无效的数据项目-dropitem">丢弃无效的数据项目 <code>DropItem</code></h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">在爬网的过程中经常会爬到一些对我们没有用或者是重复的数据，我们可以在存储这些<code>Item</code>数据之前加入一个管道来判断这些数据的可用性，保留有用的、丢弃无用的。只要在<code>process_item</code>处理方法中发起<code>scrapy.exceptions.DropItem</code>的异常就能完成<strong>丢弃</strong>的动作，并不用担心在<code>process_item</code>中引发异常会导致整个爬网过程的中止，因为管道的每次处理是针对单个<code>Item</code>对象进行的。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">在本示例中，如果文章没有标题(<code>item['title']</code>)则我们可以认为这是一个无效的数据，因为不可能出现没有标题的文章。此时，我们就会利用<code>DropItem</code>这个异常来跳出当前数据项的处理，只要将<code>process_item</code>改为:</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">if</span> item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> DropItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
  self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> item
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">这里切记一定要在<code>process_item</code>的最后返回<code>Item</code>对象，否则管道中"流动"的数据项就此被截断了。</p>
</div><div class="cl-preview-section"><h3 id="log-输出写入结果">log 输出写入结果</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">为了将爬虫写入数据库这个过程可以被输出到控制台，这样能更便于我们在开发时观察<code>MongoDBPipline</code>对象是成功地将数据项写入到MongoDB中。虽然Scrapy提供了内部的日志对象，但其实在python项目中我更喜欢使用python自带的<code>logging</code>模块，因为它的通用性可以让你的日志变得更加的灵活可用（更多的用法可以参见Python官方的<a href="https://docs.python.org/zh-cn/3/library/logging.html#">模块loggingPython 的日志记录工具</a>）。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">在导入所有依赖包之后可以加入以下的代码初始化日志模块：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">logger <span class="token operator">=</span> logging<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span>__name__<span class="token punctuation">)</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">作为一个模块级的变量，我们可以在插入数据项之后输出一个简单提示，并记录到Scrapy的状态收集器内。具体代码如下所示：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">logger<span class="token punctuation">.</span>debug<span class="token punctuation">(</span><span class="token string">"成功将数据插入至MongoDB"</span><span class="token punctuation">,</span> extra<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'spider'</span><span class="token punctuation">:</span> spider<span class="token punctuation">}</span><span class="token punctuation">)</span>
spider<span class="token punctuation">.</span>crawler<span class="token punctuation">.</span>stats<span class="token punctuation">.</span>inc_value<span class="token punctuation">(</span>
            <span class="token string">'mongodb/inserted'</span><span class="token punctuation">,</span> spider<span class="token operator">=</span>spider<span class="token punctuation">)</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><code>MongoDBPipline</code>的完整代码如下所示：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>

<span class="token keyword">import</span> pymongo
<span class="token keyword">import</span> logging
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>exceptions <span class="token keyword">import</span> DropItem

logger <span class="token operator">=</span> logging<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span>__name__<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">MongoDBPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    MongoDB数据管道
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> server<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> db_name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> col<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>server <span class="token operator">=</span> server
        self<span class="token punctuation">.</span>port <span class="token operator">=</span> port
        self<span class="token punctuation">.</span>db_name <span class="token operator">=</span> db_name
        self<span class="token punctuation">.</span>col <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>connection <span class="token operator">=</span> pymongo<span class="token punctuation">.</span>MongoClient<span class="token punctuation">(</span>self<span class="token punctuation">.</span>server<span class="token punctuation">,</span> self<span class="token punctuation">.</span>port<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> self<span class="token punctuation">.</span>connection<span class="token punctuation">[</span>self<span class="token punctuation">.</span>db_name<span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>collection <span class="token operator">=</span> self<span class="token punctuation">.</span>db<span class="token punctuation">[</span>self<span class="token punctuation">.</span>col<span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>connection<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

    @<span class="token builtin">classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
        server <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'MONGODB_SERVER'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        port <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>getint<span class="token punctuation">(</span><span class="token string">'MONGODB_PORT'</span><span class="token punctuation">)</span>
        db_name <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'MONGODB_DB'</span><span class="token punctuation">)</span>
        collection_name <span class="token operator">=</span> crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'MONGODB_COLLECTION'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>server<span class="token punctuation">,</span> port<span class="token punctuation">,</span> db_name<span class="token punctuation">,</span> collection_name<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> DropItem<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>debug<span class="token punctuation">(</span><span class="token string">"成功将数据插入至MongoDB"</span><span class="token punctuation">,</span> extra<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'spider'</span><span class="token punctuation">:</span> spider<span class="token punctuation">}</span><span class="token punctuation">)</span>
        spider<span class="token punctuation">.</span>crawler<span class="token punctuation">.</span>stats<span class="token punctuation">.</span>inc_value<span class="token punctuation">(</span>
            <span class="token string">'mongodb/inserted'</span><span class="token punctuation">,</span> spider<span class="token operator">=</span>spider<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
</code></pre>
</div><div class="cl-preview-section"><h3 id="配置mongodbpipline">配置<code>MongoDBPipline</code></h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">既然我们已经完成了<code>MongoDBPipline</code>的开发，那接下来应如何如何将这个管道接入到我们的爬虫项目中来呢？</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">首先在 <code>settings.py</code>中添加MongoDB的基本配置信息，虽然现在还没有安装MongoDB但请不要着急，我们可以先将配置写入，安装MongoDB时根据我们的配置来建立数据库和集合就可以了。</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">MONGODB_SERVER <span class="token operator">=</span> <span class="token string">"localhost"</span>	    <span class="token comment"># MongoDB 服务器地址</span>
MONGODB_PORT <span class="token operator">=</span> <span class="token number">27017</span>		          <span class="token comment"># MongoDB 服务器的访问端口</span>
MONGODB_DB <span class="token operator">=</span> <span class="token string">"netease"</span>				    <span class="token comment"># MongoDB 采用的数据库名</span>
MONGODB_COLLECTION <span class="token operator">=</span> <span class="token string">"articles"</span>	  <span class="token comment"># 写入的集合名称</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">接下来，最重要的一步就是将<code>MongoDBPipline</code>加入到的管道配置信息中了。要将自定义的管道对象接入至Scrapy需要在<code>ITEM_PIPELINES</code>配置项内加入管道对象的python包全名称:</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'netease_crawler.pipelines.MongoDBPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span>
<span class="token punctuation">}</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">最后的<code>300</code>指的是优先级，这个数值越大优先级将会越低。取值范围在<code>0</code>-<code>1000</code>之内任意取值。</p>
</div><div class="cl-preview-section"><h4 id="如何安装-mongodb---docker" style="font-size: 26px;">如何安装 MongoDB - Docker</h4>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">正如前文安装Redis那样，我推荐使用Docker来安装mongo。首先从docker的官方镜像库中找到由mongoDB官方提供的镜像：</p>
</div><div class="cl-preview-section"><pre><code>$ docker search mongo
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">通过<code>pull</code>指令将"mongo"镜像拉取至本地：</p>
</div><div class="cl-preview-section"><pre><code>$ docker pull mongo
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">MongoDB的默认数据访问端口为27017，数据文件的存储路径为<code>/data/db</code> ，那么我们就将docker容器的27017端口映射到本机，同时将docker容器的数据目录挂载到当前工作目录下的<code>db</code>目录中，具体指令如下所示：</p>
</div><div class="cl-preview-section"><pre><code>$ docker run -p 27017:27017 -v $PWD/db:/data/db -d mongo
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">最后，运行的<code>ps</code>指令查看一下mongo是否被正常地运行起来：</p>
</div><div class="cl-preview-section"><pre><code>$ docker ps
</code></pre>
</div><div class="cl-preview-section"><h4 id="使用mongodb-compass-查看爬取结果" style="font-size: 26px;">使用MongoDB Compass 查看爬取结果</h4>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">MongoDB官方提供了一个非常实用的数据库管理工具：<a href="https://docs.mongodb.com/compass/current/install/">MongoDB Compass</a>，你可以访问上述链接下载与你操作系统相匹配的运行版本安装使用。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">运行的MongoDB Compass, 会看到以下要求连接MongoDB的界面 :<br>
<img src="http://img.mukewang.com/5ceb611a00018ebf27841784.png" alt="图片描述" data-original="http://img.mukewang.com/5ceb611a00018ebf27841784.png" class="" style="cursor: pointer;">我们可以直接按默认值来连接就好了。进入MongoDB Compass的管理界面会看到MongoDB内置的三个系统数据库。直接点+号创建一个新的数据库。<br>
<img src="http://img.mukewang.com/5ceb61370001ab4227841784.png" alt="图片描述" data-original="http://img.mukewang.com/5ceb61370001ab4227841784.png" class="" style="cursor: pointer;"><img src="http://img.mukewang.com/5ceb614d0001fa6f27841784.png" alt="图片描述" data-original="http://img.mukewang.com/5ceb614d0001fa6f27841784.png" class="" style="cursor: pointer;">按我们之前的配置的数据库名(Database Name) 就用<code>netease</code> 默认集合名称(Collection Name)就使用<code>articles</code>，完成输入后点击"CREATE DATABASE"就可以轻松地创建好MongoDB的数据库环境了。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">接下来就是直接运行网易爬虫让这个高性能的爬虫全面地运转起来了!</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy crawl netease
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">让爬虫爬一会再打开MongoDB Compass可以很便快速地查看爬取后的结果:<br>
<img src="http://img.mukewang.com/5ceb616b00014bb227841784.png" alt="图片描述" data-original="http://img.mukewang.com/5ceb616b00014bb227841784.png" class="" style="cursor: pointer;"></p>
</div><div class="cl-preview-section"><h2 id="小结" style="font-size: 30px;">小结</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">本节的内容是完成一个完整爬虫项目的最后关键性的一环，在面对具有大规模海量数据的爬取目标时，有效地存储爬取结果才能给整个项目的设计画上一个句号。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果您是跟着本章内的示例一步一步走来，即使没有使用专业工具收集性能数据，你也会明显地发现你的爬虫运行速度是在不断地加快的！这就是有优化与没有优化的最大区别。我们也来回顾一下这个优化的历程：</p>
</div><div class="cl-preview-section"><ol>
<li style="font-size: 20px; line-height: 38px;">采用<code>ItemLoader</code>有效分离元素结构分析逻辑与数据结构，可以让内容分析的代码变得更为易读，能在一个分析代码中适应多种不同的页面元素结构。</li>
<li style="font-size: 20px; line-height: 38px;">采用基于Redis的去重过滤器可以有效地避免去重文件过大而被撑爆的风险。</li>
<li style="font-size: 20px; line-height: 38px;">在Redis去重过滤器的基本上使用性能更好的布隆算法使去重过程进一步提速，对于网易这类到处充斥着重复链接的网站效果最为明显。</li>
<li style="font-size: 20px; line-height: 38px;">用MongoDB作为后端存储可以避免数据结果文件过大而无法打开的囧境，并且还可以根据日后收集的数据量进行动态扩展，让爬虫项目变得更有弹性。</li>
</ol>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><img src="http://img.mukewang.com/5cf4fac20001cd0f16000880.jpg" alt="图片描述" data-original="http://img.mukewang.com/5cf4fac20001cd0f16000880.jpg" class="" style="cursor: pointer;"></p>
</div></div>
            </div>
                            <!-- 买过的阅读 -->
                <div class="art-next-prev clearfix">
                                                                        <!-- 已买且开放 或者可以试读 -->
                            <a href="/read/34/article/319">
                                                    <div class="prev l clearfix">
                                <div class="icon l">
                                    <i class="imv2-arrow3_l"></i>
                                </div>
                                <p>
                                    14 高效的布隆过滤器 - RedisBloomDupeFilter
                                </p>
                            </div>
                        </a>
                                                                                            <!-- 已买且开放 或者可以试读 -->
                            <a href="/read/34/article/321">
                                                    <div class="next r clearfix">
                                <p>
                                    16 增量式爬虫与增量爬网策略设计
                                </p>
                                <div class="icon r">
                                    <i class="imv2-arrow3_r"></i>
                                </div>

                            </div>
                        </a>
                                    </div>
                    </div>
        <div class="comments-con js-comments-con" id="coments_con">
        </div>



    </div>
    
    
    

</div>
 
<!-- 专栏介绍页专栏评价 -->

<!-- 专栏介绍页底部三条评价 -->

<!-- 专栏阅读页弹层目录和介绍页页面目录 -->

<!-- 专栏阅读页发布回复 -->

<!-- 专栏阅读页发布评论 -->

<!-- 专栏阅读页底部评论 -->

<!-- 专栏阅读 单个 评论 -->

<!-- 新增回复和展开三条以外回复 -->

<!-- 立即订阅的弹窗 -->












</div></body></html>