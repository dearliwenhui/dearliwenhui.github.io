<html><head><meta charset="utf-8"><title>05 Python 世界最流行的网络爬虫框架 Scrapy-慕课专栏</title>
			<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
			<meta name="renderer" content="webkit">
			<meta property="qc:admins" content="77103107776157736375">
			<meta property="wb:webmaster" content="c4f857219bfae3cb">
			<meta http-equiv="Access-Control-Allow-Origin" content="*">
			<meta http-equiv="Cache-Control" content="no-transform ">
			<meta http-equiv="Cache-Control" content="no-siteapp">
			<link rel="apple-touch-icon" sizes="76x76" href="https://www.imooc.com/static/img/common/touch-icon-ipad.png">
			<link rel="apple-touch-icon" sizes="120x120" href="https://www.imooc.com/static/img/common/touch-icon-iphone-retina.png">
			<link rel="apple-touch-icon" sizes="152x152" href="https://www.imooc.com/static/img/common/touch-icon-ipad-retina.png">
			<link href="https://moco.imooc.com/captcha/style/captcha.min.css" rel="stylesheet">
			<link rel="stylesheet" href="https://www.imooc.com/static/moco/v1.0/dist/css/moco.min.css?t=201907021539" type="text/css">
			<link rel="stylesheet" href="https://www.imooc.com/static/lib/swiper/swiper-3.4.2.min.css?t=201907021539">
			<link rel="stylesheet" href="../zhuanlanChapter-less.css?v=201907051055" type="text/css">
			<link charset="utf-8" rel="stylesheet" href="https://www.imooc.com/static/lib/ueditor/themes/imooc/css/ueditor.css?v=201907021539"><link rel="stylesheet" href="https://www.imooc.com/static/lib/baiduShare/api/css/share_style0_16.css?v=6aba13f0.css"></head>
			<body><div id="main">

<div class="container clearfix" id="top" style="display: block; width: 1134px;">
    
    <div class="center_con js-center_con l" style="width: 1134px;">
        <div class="article-con">
                            <!-- 买过的阅读 -->
                <div class="map">
                    <a href="/read" target="_blank"><i class="imv2-feather-o"></i></a>
                    <a href="/read/34" target="_blank">从 0 开始学爬虫</a>
                    <a href="" target="_blank">
                        <span>
                            / 2-1 05 Python 世界最流行的网络爬虫框架 Scrapy
                        </span>
                    </a>
                </div>

            


            <div class="art-title" style="margin-top: 0px;">
                05 Python 世界最流行的网络爬虫框架 Scrapy
            </div>
            <div class="art-info">
                
                <span>
                    更新时间：2019-07-03 20:08:02
                </span>
            </div>
            <div class="art-top">
                                <img src="https://img2.mukewang.com/5ce2552e0001373406400360.jpg" alt="">
                                                <div class="famous-word-box">
                    <img src="https://www.imooc.com/static/img/column/bg-l.png" alt="" class="bg1 bg">
                    <img src="https://www.imooc.com/static/img/column/bg-r.png" alt="" class="bg2 bg">
                    <div class="famous-word">从不浪费时间的人，没有工夫抱怨时间不够。<p class="author">——杰弗逊</p></div>
                </div>
                            </div>
            <div class="art-content js-lookimg">
                <div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">本节内容会带你初步了解构建网络爬虫的优秀框架 Scrapy，迈出从原始人式的手写爬虫步入工程化、专业化爬虫的第一步。</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;">scrapy 简介 —— 不讲结构只讲作用（简单）重点讲讲并行计算能力</li>
<li style="font-size: 20px; line-height: 38px;">scrapy 的安装</li>
<li style="font-size: 20px; line-height: 38px;">scrapy 的最基本命令<code>startproject</code> 的使用，构建 scrapy 项目结构</li>
<li style="font-size: 20px; line-height: 38px;">scrapy 项目结构说明，scrapy 文件与目录的作用</li>
<li style="font-size: 20px; line-height: 38px;">scrapy 其它常用指令的介绍</li>
</ul>
</div><div class="cl-preview-section"><h2 id="scrapy-简介" style="font-size: 30px;">scrapy 简介</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy 是一个基于Twisted的异步处理框架，是纯 Python 实现的爬虫框架，其架构清晰，<strong>模块之间的耦合程度低，可扩展性极强</strong>，可以灵活完成各种需求。Scrapy 算得上是 Python 世界中最多人用的爬虫框架了，在时下流行的多种语言体系中属于最好的爬虫框架！但我认为它也是最难学习的框架之一。很多初学 Scarpy 的童鞋经常向我抱怨完全不清楚 Scrapy 该怎样入手，即使看的是中文的文档，也感到很难理解。我当初接触 Scrapy 时也有这样的感觉。之所以感到Scrapy难学，究其原因，是其官方文档实在太过凌乱，又缺少实用的代码例子，让人看得云里雾里，不知其所已然。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">虽然其文档不良，但却没有遮挡住它的光辉，它依然是 Python 世界中最好用的爬虫框架。其架构的设计思路、爬虫执行的效能，还有可扩展的能力都非常出众，再配以 Python 语言的简洁轻巧，使得爬虫的开发事半功倍。</p>
</div><div class="cl-preview-section"><h3 id="scrapy的优点">Scrapy的优点</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy 的最大特点是它属于一种<strong>全家桶</strong>式的框架，在架构上很特别，都是基于插件式的增量开发模式，而且它的并行运行能力非常出众，由于这些特点 Scrapy 在正儿八经的爬虫工程中被广泛应用。以下是一些Scrapy在技术上具体优点的汇总：</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;">提供了内置的HTTP缓存，以加速本地开发。</li>
<li style="font-size: 20px; line-height: 38px;">提供了自动节流调节机制，而且具有遵守robots.txt的设置的能力。</li>
<li style="font-size: 20px; line-height: 38px;">可以定义爬行深度的限制，以避免爬虫进入死循环链接。</li>
<li style="font-size: 20px; line-height: 38px;">会自动保留会话。</li>
<li style="font-size: 20px; line-height: 38px;">执行自动HTTP基本认证。 不需要明确保存状态。</li>
<li style="font-size: 20px; line-height: 38px;">可以自动填写登录表单。</li>
<li style="font-size: 20px; line-height: 38px;">Scrapy 有一个内置的中间件，可以自动设置请求中的引用（referer）头。</li>
<li style="font-size: 20px; line-height: 38px;">支持通过3xx响应重定向，也可以通过HTML元刷新。</li>
<li style="font-size: 20px; line-height: 38px;">避免被网站使用的<code>&lt;noscript&gt;</code> meta重定向困住，以检测没有JS支持的页面。</li>
<li style="font-size: 20px; line-height: 38px;">默认使用 CSS 选择器或XPath编写解析器。</li>
<li style="font-size: 20px; line-height: 38px;">可以通过Splash或任何其他技术（如Selenium）呈现JavaScript页面。</li>
<li style="font-size: 20px; line-height: 38px;">拥有强大的社区支持、丰富的插件和扩展来扩展其功能。</li>
<li style="font-size: 20px; line-height: 38px;">提供了通用的蜘蛛来抓取最常见的格式：站点地图、CSV和XML。</li>
<li style="font-size: 20px; line-height: 38px;">内置支持以多种格式（JSON、CSV、XML、JSON-lines）导出收集的数据，并将其存储在多个后端（FTP、S3、本地文件系统）中。</li>
</ul>
</div><div class="cl-preview-section"><h3 id="scrapy-的缺点">Scrapy 的缺点</h3>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;">由于官方文档很乱，学习曲线相对陡峭，对于初学者不容易上手</li>
<li style="font-size: 20px; line-height: 38px;">配置项目繁多，使用起来复杂</li>
</ul>
</div><div class="cl-preview-section"><h3 id="scrapy与pyspider的对比">Scrapy与pySpider的对比</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">拿 Scrapy 的优点与缺点相比会发现它确实是一个不错的选择，尤其将其作为正式项目的框架选择。时下也出现了不少的与之争锋的小型框架，比较出风头的可数<a href="http://docs.pyspider.org/en/latest/Quickstart/">pySpider</a>, 在撰写本专栏之前我还专门对它作了一番深入的研究。与 Scrapy 相比 pySpider 拥有更直观的架构和更为平坦的学习曲线，对于一些简单的爬虫项目或者完全没有爬虫理论基础的同学确实也是一个值得学习的框架，但对于数据量庞大，爬取逻辑相对复杂（反爬）的项目时我还是倾向于 Scrapy，它已经历了多年被实用性验证，而且也拥有极为庞大的社区资源，在面对各种爬虫项目所涉及到的问题都会有相应的解决办法。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">本专栏我之所以全部基于 Scrapy 是因为考虑到读者从中可以学习到的内容能被真正地用在实际的工作中，由于Scrapy所覆盖的问题域较广，对于我们在掌握背后的理论也会有很大的帮助作用。</p>
</div><div class="cl-preview-section"><h2 id="scrapy-的安装" style="font-size: 30px;">scrapy 的安装</h2>
</div><div class="cl-preview-section"><h4 id="mac下安装scrapy" style="font-size: 26px;">Mac下安装Scrapy</h4>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy 的安装非常简单，在 Python2.x 的虚环境内直接执行以下的指令即可：</p>
</div><div class="cl-preview-section"><pre><code>(venv) macOS $ pip install scrapy
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy 被一直诟病不支持 Python3, 但最近Scrapy 也作出了更新，推出了 Python3 的版本，可以按以下的方法来安装：</p>
</div><div class="cl-preview-section"><pre><code>$ virtualenv -p Python3 venv # 安装python3虚环境
$ . venv/bin/activate        # 激活虚环境
(venv) $ pip install scrapy3 # 安装scrapy for Python3版本
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">scrapy 安装成功后除了提供它的基础类库以外还有方便实用的命令行工具(cli)，接下来的内容将会再介绍一些常用的命令行工具。</p>
</div><div class="cl-preview-section"><h4 id="windows-下安装scrapy" style="font-size: 26px;">Windows 下安装Scrapy</h4>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果直接安装：</p>
</div><div class="cl-preview-section"><pre><code>c:\pip install scrapy
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">很大可能会出现<code>Microsoft Visual C++ 14.0 is required. Get it with "Microsoft Visual C++ Build Tools": http://landinghub.visualstudio.com/visual-cpp-build-tools</code>的错误，下面是解决方法：</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong>1. 安装Wheel</strong></p>
</div><div class="cl-preview-section"><pre><code>c:\ pip install wheel
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong>2. 安装Twisted</strong></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">你可以在下面的链接中选中与你操作系统及 Python 版本相符的Twisted安装包。下面链接引用至<a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/">pythonlibs</a>这个网址下载与你环境对应的Twisted的whl包。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong>Twisted, an event-driven networking engine.</strong></p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;"><a href="https://download.lfd.uci.edu/pythonlibs/q5gtlas7/Twisted-19.2.0-cp27-cp27m-win32.whl">Twisted‑19.2.0 for python2.7 &amp; 32位 Windows</a></li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://download.lfd.uci.edu/pythonlibs/q5gtlas7/Twisted-19.2.0-cp27-cp27m-win_amd64.whl">Twisted‑19.2.0 for python2.7 &amp; 64位 Windows</a></li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://download.lfd.uci.edu/pythonlibs/q5gtlas7/Twisted-19.2.0-cp35-cp35m-win32.whl">Twisted‑19.2.0  for python3.5 &amp; 32位 Windows</a></li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://download.lfd.uci.edu/pythonlibs/q5gtlas7/Twisted-19.2.0-cp35-cp35m-win_amd64.whl">Twisted‑19.2.0 for python3.5 &amp; 64位 Windows</a></li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://download.lfd.uci.edu/pythonlibs/q5gtlas7/Twisted-19.2.0-cp36-cp36m-win32.whl">Twisted‑19.2.0  for python3.6 &amp; 32位 Windows</a></li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://download.lfd.uci.edu/pythonlibs/q5gtlas7/Twisted-19.2.0-cp36-cp36m-win_amd64.whl">Twisted‑19.2.0  for python3.6 &amp; 64位 Windows</a></li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://download.lfd.uci.edu/pythonlibs/q5gtlas7/Twisted-19.2.0-cp37-cp37m-win32.whl">Twisted‑19.2.0  for python3.7 &amp; 32位 Windows</a></li>
<li style="font-size: 20px; line-height: 38px;"><a href="https://download.lfd.uci.edu/pythonlibs/q5gtlas7/Twisted-19.2.0-cp37-cp37m-win_amd64.whl">Twisted‑19.2.0  for python3.7 &amp; 64位 Windows</a></li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">下载后进入whl文件所在路径，执行以下的指令(以下为python3.6及windows64位版本的whl):</p>
</div><div class="cl-preview-section"><pre><code>c:\pip install Twisted‑19.2.0‑cp36‑cp36m‑win_amd64.whl
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong>3. 安装scrapy</strong></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">下载<a href="https://download.lfd.uci.edu/pythonlibs/q5gtlas7/Scrapy-1.6.0-py2.py3-none-any.whl">Scrapy‑1.6.0‑py2.py3‑none‑any.whl</a> 并进入whl包所在路径之后执行：</p>
</div><div class="cl-preview-section"><pre><code>c:\pip install Scrapy-1.6.0-py2.py3-none-any.whl
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">完成安装后在命令行执行:</p>
</div><div class="cl-preview-section"><pre><code>c:\scrapy -h
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果能正常输出scrapy的命令帮助信息则表明安装成功。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong>4. 运行scrapy项目</strong></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果安装完成后在运行scrapy项目时报以下的错：</p>
</div><div class="cl-preview-section"><pre><code>no module named win32api
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">则表示Windows系统中，python因为原生并不能访问windows的api，所以需要额外安装pypiwin32库。</p>
</div><div class="cl-preview-section"><pre><code>pip install pypiwin32
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果不想这么折腾那就直接换掉操作系统，毕竟python在linux与unix环境才是天生强大的存在。</p>
</div><div class="cl-preview-section"><h2 id="构建-scrapy-项目结构" style="font-size: 30px;">构建 scrapy 项目结构</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">scrapy 的项目对目录结构有严格要求，为了简化这个构建指定目录的重复性过程，我们可以使用scrapy内置的<code>startproject</code>指令来快速构建scrapy项目。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><code>startproject</code>的指令模式如下:</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy startproject &lt;项目名称&gt;
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">项目名称必须以英文开头，多个单词之间可以用下划线作(<code>_</code>)为连接符，切记不要采用<code>-</code>否则会报错，下面的输出就是使用了<code>-</code>作为项目名称：</p>
</div><div class="cl-preview-section"><pre><code>Error: Project names must begin with a letter and contain only letters, numbers and underscores
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">首先，我们创建一个名为"my_crawler"的爬虫项目：</p>
</div><div class="cl-preview-section"><pre><code>(venv) macOS$ scrapy startproject my_crawler 
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">当<code>startproject</code>被成功执行，将会在控制台看到以下的输出信息:</p>
</div><div class="cl-preview-section"><pre><code>(venv) macOS:scrapy-courses raymacbook$ scrapy startproject my_crawler
New Scrapy project 'my_crawler', using template directory '/Users/ray/Projects/scrapy-courses/venv/lib/python3.7/site-packages/scrapy/templates/project', created in:
    /Users/ray/Projects/scrapy-courses/my_crawler

You can start your first spider with:
    cd my_crawler
    scrapy genspider example example.com
(venv) macOS:scrapy-courses macbook$ 
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">上述的输出提示的意思是我们可以进入<code>my_crawler</code>目录并执行<code>scrapy genspider 项目名 目标网站地址</code>创建scrapy项目中的爬虫类。在此之前先让我们来了解<code>startproject</code> 指令为我们创建的哪些文件、目录，以及它们的作用是什么。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">此时我们就可以开始scrapy的编程了。</p>
</div><div class="cl-preview-section"><h2 id="项目结构说明" style="font-size: 30px;">项目结构说明</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">展开"my_crawler"目录可以看到以下的目录结构：</p>
</div><div class="cl-preview-section"><pre><code>my_crawler
├── my_crawler         # 爬虫项目包目录
│   ├── __init__.py 
│   ├── items.py        # Item定义文件
│   ├── middlewares.py  # 自定义中间件
│   ├── pipelines.py    # 自定义管道
│   ├── settings.py     # 项目配置文件
│   └── spiders         # 蜘蛛类的存放目录
│       └── __init__.py
└── scrapy.cfg          # Scrapy 运行配置
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">一开始你可能会对 Scrapy 为什么建立一个与项目同名的源码目录感到奇怪，在最初接触 Scrapy时我也对此表示过疑惑。直到使用了一段时间以后才发现这种结构还是相当合理的。作者当时可能是出于以下几点的考虑：</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;">打包python工程生成安装文件，相应的"<a href="http://setup.py">setup.py</a>"与编辑目录会与源码目录置于同层</li>
<li style="font-size: 20px; line-height: 38px;">打包后发布工程至pypi(python官方的安装包库)时项目名称可以与源码目录保持一至</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">为了不产生不必要的麻烦，我建议你在没有完全对Scrapy了解之前不要按照个人喜好来修改目录与文件的命名。毕竟我们是在别人的思路上进行开发，所以还是先按照官方所制定的规则来学习，这样的话会少走很多弯路。</p>
</div><div class="cl-preview-section"><h2 id="scrapy-其它常用指令的介绍" style="font-size: 30px;">scrapy 其它常用指令的介绍</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy 给我们提供了两种类型的命令：项目命令（Project-specific）需要进入项目目录执行才可生效，全局命令则不需要进入项目。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">所有的命令行工具都会以如下的调用格式提供：</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy &lt;命令&gt; [选项] [参数]
</code></pre>
</div><div class="cl-preview-section"><h4 id="全局指令" style="font-size: 26px;">全局指令</h4>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy 提供的全局命令(只能在 Scrapy 项目目录之外运行)主要包括以下这些:</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy startproject &lt;项目名&gt;</code> - 初始化爬虫项目，创建基本目录与必要的文件。</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy settings --get &lt;配置项的名称&gt;</code> - 在项目中运行时，该命令将会输出项目的设定值，否则输出Scrapy默认设定。</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy runspider &lt;spider_file.py&gt;</code> - 在未创建项目的情况下，运行一个编写在Python文件中的spider。</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy shell &lt;url&gt;</code> - 以给定的URL启动Scrapy指令外壳,可以在命令行中直接操作scrapy内置的python对象，我觉得并没有什么实用性，这些运行期变量我们都可以借助pyCharm的调试器看到,官方文档可参考<a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/shell.html#topics-shell">Scrapy终端(Scrapy shell)</a>。</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy fetch &lt;url&gt;</code> - 使用Scrapy下载器(downloader)下载给定的URL，并将获取到的内容打印到控制台上。</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy view &lt;url&gt;</code> - 在浏览器中打开给定的URL，并用一个Scrapy spider获取目标URL，并将结构显示到浏览器中。</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy version [-v]</code> - 输出Scrapy版本。配合 -v 运行时，该命令同时输出Python, Twisted以及平台的信息，方便bug提交。</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">除了 <code>startproject</code>是常用命令之外，只有<code>fetch</code>和<code>view</code>指命比较有用，其它的指令作用不大。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong><code>fetch</code> 指令</strong></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">这个指令可以理解为<code>curl</code>指令的最简化版本，就是直接从指定的 url 上下载网页内容，然后就输出到控制台,效果如下：<br>
<img src="http://img.mukewang.com/5cdd527e00016f5f09610666.png" alt="图片描述" data-original="http://img.mukewang.com/5cdd527e00016f5f09610666.png" class="" style="cursor: pointer;"></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">可见，它的输出只不过是杂乱无章的一大堆内容，实用性很差。但如果加入另一个参数<code>--headers</code>这个指令就变得有用得多：</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy fetch --nolog --headers http://www.baidu.com
&gt; Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
&gt; Accept-Language: en
&gt; User-Agent: Scrapy/1.0.1 (+https://scrapy.org)
&gt; Accept-Encoding: gzip,deflate
&gt;
&lt; Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform
&lt; Content-Type: text/html
&lt; Date: Sat, 20 Apr 2019 08:19:34 GMT
&lt; Last-Modified: Mon, 23 Jan 2017 13:27:57 GMT
&lt; Pragma: no-cache
&lt; Server: bfe/1.0.8.18
&lt; Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">使用<code>--headers</code>之后我们可以很快速地看到 Scrapy 向目标网页发出的请求头与响应头的详细内容，这对于我们进行爬网分析与设计会起到很大的作用。本专栏后续的章节中也会采用此命令来进行分析，此时你也可以动手试试对不同网址的请求与返回的结果是什么样子的。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong><code>view</code> 指令</strong></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">用对象向目标网站发出请求返回的内容，很多时候与我们直接打开浏览器所看到的并不一样，尤其是那些重度运用javascript技术的网站，<code>view</code>指令就是直接用 Scrapy 内置的<code>Request</code>对象向目标网站发出请求，然后将返回内容存到本地的临时文件中再用浏览器打开。这个指令的意义在于让我们清楚地知道，用<code>Request</code>对象发出请求后到底会得到些什么，就以淘宝为例，以下第一张图是用浏览器直接打开的网页，第二张图是用<code>view</code>指令打开淘宝的效果:<br>
<img src="http://img.mukewang.com/5cdd567d0001183127882058.png" alt="图片描述" data-original="http://img.mukewang.com/5cdd567d0001183127882058.png" class="" style="cursor: pointer;"></p>
</div><div class="cl-preview-section"><pre><code>$ scrapy view http://www.taobao.com
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><img src="http://img.mukewang.com/5cdd56a1000150f126442060.png" alt="图片描述" data-original="http://img.mukewang.com/5cdd56a1000150f126442060.png" class="" style="cursor: pointer;"><br>
对比之后可以发现很多内容在用<code>Request</code>发起请求的时候是获取不到的。</p>
</div><div class="cl-preview-section"><h4 id="项目（project-only）命令" style="font-size: 26px;">项目（Project-only）命令:</h4>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">以下这些指令是必须先进入项目目录后才能使用的命令：</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy crawl &lt;蜘蛛名&gt;</code> - 使用指定的蜘蛛执行爬取。</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy genspider</code> - 在当前项目中创建spider。这仅仅是创建spider的一种快捷方法。该方法可以使用提前定义好的模板来生成spider。</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy list</code>- 列出当前项目中有多少个可用的蜘蛛（不实用）</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy check [-l] &lt;蜘蛛名&gt;</code> - 运行contract检查。（没有什么实质作用，contract是一种非常简陋的测试机制，不推荐使用）</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy edit &lt;蜘蛛名&gt;</code> - 启用一个IDE编辑蜘蛛</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy deploy [ &lt;target:project&gt; | -l &lt;target&gt; | -L ]</code> - 将项目部署到Scrapyd服务</li>
<li style="font-size: 20px; line-height: 38px;"><code>scrapy bench</code> - 运行benchmark测试</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong><code>crawl</code> 指令</strong></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><code>crawl</code>指令是 Scrapy 众多内置指令中使用频次最高的一个，每次执行爬取你都需要运行它，例如:</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy crawl news_spider
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">此命令一旦执行，就会将所有的输出信息打印到当前终端窗口内，直至爬虫完成所有的爬取任务为止。在此不再作过多的赘述，在后面的内容里我们将会经常与它见面，当开发了具体的蜘蛛代码时再回过头来仔细学习这个命令。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong><code>genspider</code> 指令</strong></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><code>genspider</code>指令是一个对于Scrapy初学者非常有用的指令，顾名思义它就是用来帮助我们生成蜘蛛代码框架构的，它的指令结构如下:</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy genspider [-t 模板名] &lt;蜘蛛名&gt; &lt;域&gt;
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">模板名参数提供以下4种常用的蜘蛛模板：</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;">basic - 默认，创建基本的蜘蛛</li>
<li style="font-size: 20px; line-height: 38px;">crawl - 创建基于<code>CrawlSpider</code>的蜘蛛</li>
<li style="font-size: 20px; line-height: 38px;">csvfeed - 创建基于<code>CsvFeedSpider</code>的蜘蛛</li>
<li style="font-size: 20px; line-height: 38px;">xmlfeed - 创建基于<code>XmlFeedSpider</code>的蜘蛛</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">此处请容我卖个关子，先不展开对具体蜘蛛的作用的解释，后面的内容中会一一有针对性地对它们进行实践与解释。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">创建一个爬取新浪新闻的普通蜘蛛:</p>
</div><div class="cl-preview-section"><pre><code>$ scrapy genspider news http://www.sina.com
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">当指令执行成功后就会在 <code>[项目名]/[项目名]/spiders/</code> 目录下找到一个<code>news.py</code>的蜘蛛源码文件:</p>
</div><div class="cl-preview-section"><pre><code>news_crawler
├── __init__.py
├── items.py
├── middlewares.py
├── pipelines.py
├── settings.py
└── spiders
    └── news.py
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">打开 <code>news.py</code>:</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">NewsSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 生成蜘蛛后Scrapy会将蜘蛛名首字母大写并在其后加Spider作为蜘蛛的类名</span>
    name <span class="token operator">=</span> <span class="token string">'news'</span>                               <span class="token comment"># 蜘蛛名</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.sina.com'</span><span class="token punctuation">]</span>   <span class="token comment"># 在genspider指定的域</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://http://www.sina.com/'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">用<code>startproject</code>和<code>genspider</code>两个指令就已经可以创建一个最基本可以运行的爬虫项目了。</p>
</div><div class="cl-preview-section"><h2 id="小结" style="font-size: 30px;">小结</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">至此，我们已经对 Scrapy 的安装和基本使用建立了一个基本的认识。也从 Scrapy 那纷繁复杂的指令中集中了解了哪些指令是必须学的，哪些不过是摆设。如果想在爬虫的开发路上走得更加顺畅，试试使用 Ubuntu 或者其它的 Linux 来开发，这样的话，你会更加理解为什么我用如此之长的篇幅来讲述“指令”这一强大的工具。<br>
<img src="http://img.mukewang.com/5cde268e0001397816000682.jpg" alt="图片描述" data-original="http://img.mukewang.com/5cde268e0001397816000682.jpg" class="" style="cursor: pointer;"></p>
</div></div>
            </div>
                            <!-- 买过的阅读 -->
                <div class="art-next-prev clearfix">
                                                                        <!-- 已买且开放 或者可以试读 -->
                            <a href="/read/34/article/308">
                                                    <div class="prev l clearfix">
                                <div class="icon l">
                                    <i class="imv2-arrow3_l"></i>
                                </div>
                                <p>
                                    04 动手开发最简单的单文件爬虫
                                </p>
                            </div>
                        </a>
                                                                                            <!-- 已买且开放 或者可以试读 -->
                            <a href="/read/34/article/304">
                                                    <div class="next r clearfix">
                                <p>
                                    06 新闻供稿专用爬虫开发实践
                                </p>
                                <div class="icon r">
                                    <i class="imv2-arrow3_r"></i>
                                </div>

                            </div>
                        </a>
                                    </div>
                    </div>
        <div class="comments-con js-comments-con" id="coments_con">
        </div>



    </div>
    
    
    

</div>
 
<!-- 专栏介绍页专栏评价 -->

<!-- 专栏介绍页底部三条评价 -->

<!-- 专栏阅读页弹层目录和介绍页页面目录 -->

<!-- 专栏阅读页发布回复 -->

<!-- 专栏阅读页发布评论 -->

<!-- 专栏阅读页底部评论 -->

<!-- 专栏阅读 单个 评论 -->

<!-- 新增回复和展开三条以外回复 -->

<!-- 立即订阅的弹窗 -->












</div></body></html>