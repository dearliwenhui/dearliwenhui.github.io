<html><head><meta charset="utf-8"><title>22 反爬之反跟踪与随机代理-慕课专栏</title>
			<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
			<meta name="renderer" content="webkit">
			<meta property="qc:admins" content="77103107776157736375">
			<meta property="wb:webmaster" content="c4f857219bfae3cb">
			<meta http-equiv="Access-Control-Allow-Origin" content="*">
			<meta http-equiv="Cache-Control" content="no-transform ">
			<meta http-equiv="Cache-Control" content="no-siteapp">
			<link rel="apple-touch-icon" sizes="76x76" href="https://www.imooc.com/static/img/common/touch-icon-ipad.png">
			<link rel="apple-touch-icon" sizes="120x120" href="https://www.imooc.com/static/img/common/touch-icon-iphone-retina.png">
			<link rel="apple-touch-icon" sizes="152x152" href="https://www.imooc.com/static/img/common/touch-icon-ipad-retina.png">
			<link href="https://moco.imooc.com/captcha/style/captcha.min.css" rel="stylesheet">
			<link rel="stylesheet" href="https://www.imooc.com/static/moco/v1.0/dist/css/moco.min.css?t=201907021539" type="text/css">
			<link rel="stylesheet" href="https://www.imooc.com/static/lib/swiper/swiper-3.4.2.min.css?t=201907021539">
			<link rel="stylesheet" href="https://static.mukewang.com/static/css/??base.css,common/common-less.css?t=2.5,column/zhuanlanChapter-less.css?t=2.5,course/inc/course_tipoff-less.css?t=2.5?v=201907051055" type="text/css">
			<link charset="utf-8" rel="stylesheet" href="https://www.imooc.com/static/lib/ueditor/themes/imooc/css/ueditor.css?v=201907021539"><link rel="stylesheet" href="https://www.imooc.com/static/lib/baiduShare/api/css/share_style0_16.css?v=6aba13f0.css"></head>
			<body><div id="main">

<div class="container clearfix" id="top" style="display: block; width: 1134px;">
    
    <div class="center_con js-center_con l" style="width: 1134px;">
        <div class="article-con">
                            <!-- 买过的阅读 -->
                <div class="map">
                    <a href="/read" target="_blank"><i class="imv2-feather-o"></i></a>
                    <a href="/read/34" target="_blank">从 0 开始学爬虫</a>
                    <a href="" target="_blank">
                        <span>
                            / 5-6 22 反爬之反跟踪与随机代理
                        </span>
                    </a>
                </div>

            


            <div class="art-title" style="margin-top: 0px;">
                22 反爬之反跟踪与随机代理
            </div>
            <div class="art-info">
                
                <span>
                    更新时间：2019-06-17 10:56:38
                </span>
            </div>
            <div class="art-top">
                                <img src="https://img4.mukewang.com/5d033e6c0001c20a06400359.jpg" alt="">
                                                <div class="famous-word-box">
                    <img src="https://www.imooc.com/static/img/column/bg-l.png" alt="" class="bg1 bg">
                    <img src="https://www.imooc.com/static/img/column/bg-r.png" alt="" class="bg2 bg">
                    <div class="famous-word">学习要注意到细处，不是粗枝大叶的，这样可以逐步学习、摸索，找到客观规律。 <p class="author">—— 徐特立</p></div>
                </div>
                            </div>
            <div class="art-content js-lookimg">
                <div><div class="cl-preview-section"><h2 id="重新认识-scrapy-的自动降速中间件" style="font-size: 30px;">重新认识 Scrapy 的自动降速中间件</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy的蜘蛛的工作效率非常高。它们可以同时处理多个并发请求并充分利用带宽和计算能力。但这种高效在很多情况下并不是好事，因为它很容易造成目标网站的性能下载，或者由于请求过于频繁、数据下载量过大而被对方网站发觉甚至直接被禁止访问。我们的豆瓣爬虫之所以在运行一段时间后就被封IP，同一IP的过于频繁与大量的请求就是其中最大的问题。站在网站开发的角度上对于这种"非人"的请求必然可以判断是由爬虫或某些带有攻击性的机器人程度所为，当然将其IP封禁是理所当然的。那么要避免被封，降速访问就是我们第一个能想到的"无奈之举"了。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">那么我们应该如何对Scrapy进行调速呢？</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy的调速的基本原理就是调整并发数量与发出请求间的延时。对此Scrapy有以下几个标准配置选项进行设置：</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;"><code>CONCURRENT_REQUESTS</code> - Scrapy 下载器并发请求(concurrent requests)的最大值。(默认为16)</li>
<li style="font-size: 20px; line-height: 38px;"><code>CONCURRENT_REQUESTS_PER_DOMAIN</code> -  对单个网站进行并发请求的最大值。(默认为8)</li>
<li style="font-size: 20px; line-height: 38px;"><code>CONCURRENT_REQUESTS_PER_IP</code> - 对单个IP进行并发请求的最大值。如果非0，则忽略 <code>CONCURRENT_REQUESTS_PER_DOMAIN</code> 设定， 使用该设定。 也就是说，并发限制将针对IP，而不是网站。</li>
<li style="font-size: 20px; line-height: 38px;"><code>DOWNLOAD_DELAY</code> - 下载延时</li>
<li style="font-size: 20px; line-height: 38px;"><code>RANDOMIZE_DOWNLOAD_DELAY</code>- 如果启用，当从相同的网站获取数据时，Scrapy将会等待一个随机的值 (0.5到1.5之间的一个随机值 * <code>DOWNLOAD_DELAY</code>)</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">要避免出现过分频繁的访问请求，就需要在实际部署爬虫系统时设置<code>DOWNLOAD_DELAY</code>。其实Scrapy是默认启用了<code>RANDOMIZE_DOWNLOAD_DELAY</code>计算一个随机的请求延时间隔。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">如果想设置明确的<code>DOWNLOAD_DELAY</code>，就必须禁用<code>RANDOMIZE_DOWNLOAD_DELAY</code>选项。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">默认情况下<code>DOWNLOAD_DELAY</code>被设置为0。如果要将每个请求之间的间隔设置为5秒，则可以按以下方式来设置：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">RANDOMIZE_DOWNLOAD_DELAY <span class="token operator">=</span> <span class="token boolean">False</span>
DOWNLOAD_DELAY <span class="token operator">=</span> <span class="token number">5.0</span>
</code></pre>
</div><div class="cl-preview-section"><blockquote>
<p style="font-size: 20px; line-height: 38px;"><strong>技巧</strong>:如果项目中正在同时运行多个不同的蜘蛛，而不同蜘蛛之间的请求间隔又不尽相同，则可以直接在蜘蛛中设置其<code>download_delay</code>属性以对配置进行单独的覆盖。</p>
<pre class="  language-python"><code class="prism  language-python"><span class="token keyword">class</span> <span class="token class-name">MySpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
 name <span class="token operator">=</span> <span class="token string">'myspider'</span>
 download_delay <span class="token operator">=</span> <span class="token number">5.0</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
</blockquote>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">下载延时是不是越大越好呢？理论上是，但你要相对付出的就是"等待时间"，下载延时越久你要等待爬虫完成爬取的时间就越久，调整这个参数一般需要靠<strong>猜</strong>对方网站的极限值，从<code>5.0</code>开始一直向下调整，直到被封IP为止，这样就大约可以知道对方大约能接受多大的极限值。</p>
</div><div class="cl-preview-section"><h4 id="调整并发请求数" style="font-size: 26px;">调整并发请求数</h4>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">除了调整下载延时，另一个做法就是可以调整对每个域的并发请求数，使得蜘蛛变得更有“礼貌”。默认情况下，Scrapy将最多同时向任何给定的域发送8个请求，但可以通过更新<code>CONCURRENT_REQUESTS_PER_DOMAIN</code>设置来更改此值。</p>
</div><div class="cl-preview-section"><blockquote>
<p style="font-size: 20px; line-height: 38px;">注意：<code>CONCURRENT_REQUESTS</code>用于设定Scrapy的下载器在同一时间的并发请求数。调整此设置对于服务器性能/带宽来说比在同一时间抓取多个域时的目标更高。</p>
</blockquote>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">这个参数的调整办法与延时是相同的，先试验对方的<strong>极限</strong>，我在前两章设计网易爬虫时，开始是直接将<code>CONCURRENT_REQUESTS</code>上限调整到32。</p>
</div><div class="cl-preview-section"><h4 id="autothrottle" style="font-size: 26px;">AutoThrottle</h4>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">网站可以处理的请求数量差别很大。如果对每个爬取的网站进行手动调整，则可能会让你抓狂。Scrapy提供了一个自动降速(<code>AutoThrottle</code>)的扩展来解决这个问题。<code>AutoThrottle</code>根据当前Web服务器负载自动调整请求之间的延迟。它首先计算一个请求的延迟。 然后调整同一个域的请求之间的延迟，使得不超过<code>AUTOTHROTTLE_TARGET_CONCURRENCY</code>的请求将同时激活。它还确保请求在给定的时间范围内均匀分布。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">自动降速扩展是由以下几个配置项所控制</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;"><code>AUTOTHROTTLE_ENABLED</code> - 启用AutoThrottle扩展(默认为<code>False</code>)。</li>
<li style="font-size: 20px; line-height: 38px;"><code>AUTOTHROTTLE_START_DELAY</code>- 初始下载延迟(单位:秒)。</li>
<li style="font-size: 20px; line-height: 38px;"><code>AUTOTHROTTLE_MAX_DELAY</code>- 在高延迟情况下最大的下载延迟(单位秒)。</li>
<li style="font-size: 20px; line-height: 38px;"><code>AUTOTHROTTLE_TARGET_CONCURRENCY</code> - 显示每个响应的降速阀值状态。</li>
<li style="font-size: 20px; line-height: 38px;"><code>AUTOTHROTTLE_DEBUG</code> - 起用AutoThrottle调试(debug)模式，展示每个接收到的response。 您可以通过此来查看限速参数是如何实时被调整的。</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">我一般情况下会这样配置爬虫的自动降速设定：</p>
</div><div class="cl-preview-section"><pre><code>AUTOTHROTTLE_ENABLED = True # 一定要打开，否则自动降速就会禁用
AUTOTHROTTLE_START_DELAY = 5
AUTOTHROTTLE_MAX_DELAY = 60
AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0
AUTOTHROTTLE_DEBUG = False
</code></pre>
</div><div class="cl-preview-section"><h2 id="化身术" style="font-size: 30px;">化身术</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">所谓的化身术就是将爬虫的行迹进行隐藏，将其<strong>模仿</strong>人或搜索引擎蜘蛛的行为。除了上一节重点讲述的 UA，再配合上整调好的限速设定后最重要的是将请求的IP更换掉。</p>
</div><div class="cl-preview-section"><h3 id="随机代理-randomproxymiddleware">随机代理 <code>RandomProxyMiddleware</code></h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">更换IP的最佳办法当然是使用代理来访问目标网站了，这个效果就正如我们在浏览器上设置代理上网的原理是一样的。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">要让爬虫能化身万千就要有<strong>万千</strong>个UA和<strong>万千</strong>个IP，这是必备的条件。UA只要上网百度一下就可以捞出一个大全，毕竟UA的变换频次不高。但IP的变换则需要一定的代价，主要我们可以想到如下几个办法:</p>
</div><div class="cl-preview-section"><ol>
<li style="font-size: 20px; line-height: 38px;">找一个会自动变更IP的代理</li>
<li style="font-size: 20px; line-height: 38px;">用程序控制ADSL Moden重启，每次重启成功都会获得新IP</li>
<li style="font-size: 20px; line-height: 38px;">购买付费代理服务。</li>
<li style="font-size: 20px; line-height: 38px;">收集稳定可用的代理，建立一个代理池，编写一个随机代理中间件在每次发出请求前随机更换代理</li>
</ol>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">在上述的办法中我们显然会直接先第4种，采用随机代理。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">Scrapy提供了一个代理插件扩展，但只能设置一个代理地址。所以我们只能重写一个随机代理中间件下载器。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">在Scrapy中更换代理地址的办法很简单，只要设置<code>request.meta['proxy']</code>属性即可，与随机UA的做法相同，先在<code>settings.py</code>文件中增加一个配置项<code>HTTP_PROXIES</code>作为代理池存放一个可用的代理地址列表。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">然后在 <code>middlewares</code>中加入以下代码:</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>

<span class="token keyword">import</span> random


<span class="token keyword">class</span> <span class="token class-name">RandomProxyMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    随机代理。在运行时会从settings.py设置的PROXIES中随机抽取一个作为当前代理地址。
    """</span>
    @<span class="token builtin">classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>proxies<span class="token operator">=</span>crawler<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>getlist<span class="token punctuation">(</span><span class="token string">'HTTP_PROXIES'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> proxies<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>proxies <span class="token operator">=</span> proxies

    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>self<span class="token punctuation">.</span>proxies<span class="token punctuation">)</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">最后，在配置中将随机代理启用起来：</p>
</div><div class="cl-preview-section"><pre><code>DOWNLOADER_MIDDLEWARES = {
    'douban.middlewares.RandomProxyMiddleware': 501,
}
</code></pre>
</div><div class="cl-preview-section"><blockquote>
<p style="font-size: 20px; line-height: 38px;">如果你真的找不到什么代理资源，又不希望付费购买，那么还可以采用一种不可描述的大招，尽破一切IP封禁机制 (专栏结束后可加群索取或在我出版的《Python绝技 - 虫术》电子工业出版社 一书中也有此招)</p>
</blockquote>
</div><div class="cl-preview-section"><h3 id="反cookie跟踪">反cookie跟踪</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">要模拟出状态化的效果只能通过cookie或者服务端会话（session）实现，如果开启真正的服务端会话，会使服务器的容量到达低谷。因为一旦开启会话，服务器会为每个访问的客户开启一个专用的空间来保存会话。会话一般以20分钟为可用时长，而一旦访问量过大，会话空间就有可能拖垮服务器。禁用会话是开发高性能网站的基本常识，因此很多开发语言中的会话功能都是一种“伪会话”，大多都是通过向cookie写入一个会话ID来进行识别的。这样说来，cookie也就成为了唯一能跟踪客户行为的手段。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">比起会话ID，用户的登录信息才是cookie的常客，几乎所有的用户登录功能都要用Cookie来存储。如果网站开发者重视安全性，往往会对cookie中存储的值进行非对称加密，这样就会让客户端无法伪造cookie中的值。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">那么在爬虫中应该如何应对呢？</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong>1.禁用cookie</strong></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">通过禁止cookie，这是客户端主动阻止服务器写入。禁止cookie可以避免那些采用cookies识别爬虫的网站的封杀。在Scrapy爬虫中可以设置<code>COOKIES_ENABLES=FALSE</code>，即不启用cookies middleware，不向Web Server发送cookies。</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python"><span class="token comment"># settings.py</span>
COOKIES_ENABLES<span class="token operator">=</span><span class="token boolean">False</span>
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">这种方法直接、粗暴、简单。但也遇到过有些网站会发送随机cookie，如果检测到客户端没有回发随机生成的cookie，则将客户端认定为爬虫而直接封掉。另外，这种做法一旦遇到需要登录的场景就完全失效，所以说它<strong>仅仅适用于那些不需要验证登录身份</strong>的开放式网站或者页面。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;"><strong>2.合并cookie</strong></p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">也就是将每次响应收到的cookie先存起来，在下次发出请求时使用。这种做法在Scrapy中是不用设置的，正如前面所述cookies中间件是默认启用的，它会自动进行处理。</p>
</div><div class="cl-preview-section"><h3 id="反跟踪技术---refermiddleware">反跟踪技术 - <code>ReferMiddleware</code></h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">要从服务器端主动跟踪和分析客户端的异常行为，其实手段相当有限。只要深入地反思一下这个问题就能找到答案：“你可以用何种手段在网站上跟踪访客？” 首先我们知道Web服务器是无状态的，要跟踪访客的行为就需要知道客户端的某一种状态。服务端只能从请求头上得知客户端的一些基本信息。例如，通过UserAgent获取浏览器的名称和版本，通过IP地址计算归属地，通过Referer了解这个请求是从哪个页面引入的，通过查询字符串（Query String）显式地传入参数进行某些判断。而这些都是一次性信息，并不带有任何状态。</p>
</div><div class="cl-preview-section"><h3 id="referer策略">referer策略</h3>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">referer用于告诉服务器当前这个请求是由哪个页面转入的，这是一个URL值，经常用于反盗链检测（是反盗链而不是反爬）。这种手段常见于一些大型网站或者老牌网站（如百度），一旦触发了反盗链机制，所获得的网页内容就与原来的内容完全不同了，但爬虫却可能完全不知。它不会使请求失败，而是会响应写入其他版权保护信息。例如，爬取的是一张图片，但由于referer的设置违反了对方的引用策略，那么得到的可能就是一个“该图片来自XXX网站”的占位图。</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">referrer策略包含以下值：</p>
</div><div class="cl-preview-section"><ul>
<li style="font-size: 20px; line-height: 38px;">no-referrer - 最简单的策略是“no-referrer”，表示所有的请求都不带referrer。</li>
<li style="font-size: 20px; line-height: 38px;">no-referrer-when-downgrade - 主要针对于受TLS保护的URL（如HTTPS），简单地说就是在HTTPS的页面中，如果连接的资源也是HTTPS的，则发送完整的referrer，如果连接的资源是HTTP的，就不发送referrer。这是在没有特别指定referrer策略时，浏览器的默认行为。</li>
<li style="font-size: 20px; line-height: 38px;">same-origin - 对于同源的链接，会发送referrer，其他的不会。同源意味着域名需要相同，example.com和not.example.com是非同源的。</li>
<li style="font-size: 20px; line-height: 38px;">origin - 这个策略对于任何资源来说只发送源的信息，不发送完整的URL。</li>
<li style="font-size: 20px; line-height: 38px;">strict-origin - 这个策略类似于origin和no-referrer-when-downgrade的合体，如果一个HTTPS页面中链接到HTTP的页面或资源，则不会发送referrer。HTTP页面链接和HTTPS链接到HTTPS都只发送来源页面的源信息。</li>
<li style="font-size: 20px; line-height: 38px;">origin-when-cross-origin - 该策略在同源的链接中发送完整的URL，其他情况仅发送源信息。相同的域名，HTTP和HTTPS协议被认为是非同源的。</li>
<li style="font-size: 20px; line-height: 38px;">strict-origin-when-cross-origin - 对于同源请求，发送完整的URL；对于同为HTTPS的，只发送源信息；对于HTTPS页面只发送源信息；HTTPS页面中的HTTP请求不发送referrer。</li>
<li style="font-size: 20px; line-height: 38px;">unsafe-url - 这个主要是解决HTTPS页面中的HTTP资源不发送referrer的问题，它会使在HTTPS页面中的HTTP资源发送完整的referrer。</li>
<li style="font-size: 20px; line-height: 38px;">空字符串 - 空字符串表示没有referrer策略，默认为no-referrer-when-downgrade。</li>
</ul>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">那么怎么才知道目标网站采用了哪个referrer策略呢？</p>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">referrer策略会通通过以下方法声明：</p>
</div><div class="cl-preview-section"><ol>
<li style="font-size: 20px; line-height: 38px;">通过HTTP请求头中的Referrer-Policy字段。</li>
<li style="font-size: 20px; line-height: 38px;">通过meta标签，name为referrer，如：<code>&lt;meta name="referrer" content="same-origin" /&gt;</code>。</li>
<li style="font-size: 20px; line-height: 38px;">通过<code>&lt;a&gt;</code>、<code>&lt;area&gt;</code>、<code>&lt;img&gt;</code>、<code>&lt;iframe&gt;</code>、<code>&lt;link&gt;</code>元素的referrerpolicy属性。</li>
<li style="font-size: 20px; line-height: 38px;">通过<code>&lt;a&gt;</code>、<code>&lt;area&gt;&lt;link&gt;</code>元素的<code>rel=noreferrer</code>属性。</li>
<li style="font-size: 20px; line-height: 38px;">通过隐式继承。</li>
</ol>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">因此，一旦遇到具有反盗链策略的网站，就要先对上述地方进行检测，得出对方的引用策略后才能正确应对。Scrapy提供了一个<code>RefererMiddleware</code>中间件用于处理referer，但它只能用于统一地将所有请求设置为配置中指定的referrer策略，默认情况下它是被启用的。如果要关闭它，则只需要将配置文件中的<code>REFERER_ENABLED</code>设置为<code>False</code>即可。</p>
</div><div class="cl-preview-section"><pre><code>REFERER_ENABLED=False
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">通过设置<code>REFERRER_POLICY</code>可以默认启用referrer策略：</p>
</div><div class="cl-preview-section"><pre><code>REFERRER_POLICY='origin'
</code></pre>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">另外，还可以在代码中动态设置referrer策略：</p>
</div><div class="cl-preview-section"><pre class="  language-python"><code class="prism  language-python">request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'referrer_policy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'origin-when-cross-origin'</span>
</code></pre>
</div><div class="cl-preview-section"><h2 id="小结" style="font-size: 30px;">小结</h2>
</div><div class="cl-preview-section"><p style="font-size: 20px; line-height: 38px;">主要的放反技术在这两节中都分重点进行了一个介绍，这两节书的内容对于初学者的学习曲线可能会稍显陡峭，毕竟防反是一种基础网络技术的范畴，要运用得好得活学活用而且还需要对多个基础领域深入了解。所以从"基于SQL数据导出机制"一节开始我就在专栏内容里面留下一些思考的内容，而且没有给出答案。只有自己独立面对问题并经过思考寻找答案才是真正掌握一门技术的关键。同样地，在本节我也给你留了一个思考题：在如此多的防反技巧中应该如何来配置你的<code>settings.py</code>文件呢？</p>
</div></div>
            </div>
                            <!-- 买过的阅读 -->
                <div class="art-next-prev clearfix">
                                                                        <!-- 已买且开放 或者可以试读 -->
                            <a href="/read/34/article/428">
                                                    <div class="prev l clearfix">
                                <div class="icon l">
                                    <i class="imv2-arrow3_l"></i>
                                </div>
                                <p>
                                    21 反爬之客户端仿真
                                </p>
                            </div>
                        </a>
                                                                                            <!-- 已买且开放 或者可以试读 -->
                            <a href="/read/34/article/328">
                                                    <div class="next r clearfix">
                                <p>
                                    23 分布式网络爬虫
                                </p>
                                <div class="icon r">
                                    <i class="imv2-arrow3_r"></i>
                                </div>

                            </div>
                        </a>
                                    </div>
                    </div>
        <div class="comments-con js-comments-con" id="coments_con">     <div class="number">精选留言 <span class="js-number">0</span></div>     <div class="comments">         <div class="input-fake js-showcommentModal">             欢迎在这里发表留言，作者筛选后可公开显示         </div>                      <div class="noData">                 <p>                     <i class="imv2-error_c"></i>                 </p>                 <p>目前暂无任何讨论</p>             </div>              </div>  </div>



    </div>
    
    
    

</div>
 
<!-- 专栏介绍页专栏评价 -->

<!-- 专栏介绍页底部三条评价 -->

<!-- 专栏阅读页弹层目录和介绍页页面目录 -->

<!-- 专栏阅读页发布回复 -->

<!-- 专栏阅读页发布评论 -->

<!-- 专栏阅读页底部评论 -->

<!-- 专栏阅读 单个 评论 -->

<!-- 新增回复和展开三条以外回复 -->

<!-- 立即订阅的弹窗 -->












</div></body></html>